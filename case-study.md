# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно обрабатывала входной файл размером в 100 мегабайт за 36 секунды и 2404 мегабайта памяти, но по условиям, данная программа не должна была потреблять больше 70 мегабайт памяти, что не соотвествовало действительности.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: замерял объём потребялемой памяти до и после выполнения программы.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 20 секунд.

Вот как я построил `feedback_loop`:
1. Делал нельбошие изменения в коде.
2. Запускал тесты производительности (потребления памяти, скорости работы).
3. Проверял, если есть положительные резутаты, коммитил код. В случае регресса - откатывал изменения.
4. Небольшими итерациями добился до нужного результата.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался `ruby prof graf`, `memory_profiler`, `valgring-massif`, `ruby_prof_memory_callgrind`

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- с помощью `ruby prof graf` - было замечано, что на второй цикл уходит половина времени от обработки файла
```ruby
user_objects.each do |user_object|
    prepare_stats(report, user_object)
    progress_bar.increment
end
```
- решил добиться обработки данных в один проход
- метрика изменилась в положительную сторону,  c 36 сек до 25, потребление памяти сократилось 2404 до 935 мегабайт
- Отчёт перестал показывать дополнительную итерацию

### Ваша находка №2
- `memory profiler` - показал огромное кол-во использования строк
- решил указать для интепретатора, что строки изменяются не будут `frozen_string_literal: true`, так же вынес все строки в константы
- снизился расход памяти с 1058 до 1018 мегабайт
- общеё количество используемых строк уменьшилось

### Ваша находка №3
- `memory profiler` - тем не менее показывал использование лишних структур в виде массисовов и создания дополнительных ненужных переменных
- упростил структуру, убрал всевозможные итерирования массиов и создания дополнительных объектов, так же удалил класс User, заменив на обычный хеш
- снизился расход памяти с 1018 до 958 мегабайт (при полном прохождении файла). Общее время прохождения скрипта уменьшилось с 25 до 19 секунд.
- на выборке в 100к `memory_profilier` стабильно показывает снижение с 124 мегабайт, до 78.

### Ваша находка №4
- после всех исправление `memory profiler` показывает на потребление памяти в методе `split`
```
 36.74 MB  /Users/markII/src/cources/rails-optimization-2-task2/lib/task.rb:47 (split)
   9.12 MB  /Users/markII/src/cources/rails-optimization-2-task2/lib/task.rb:66(oj.dump)
```
но к сожаление эту строку оптимизировать не получиться, т.к. данные применяются на всё протяжение скрипта, поэтому здесь обратим внимание на потребленмие памяти в oj.dump.
Так же из отчётов `valgring-massif` можно заметить, то что рост памяти идёт на всём протяжение программмы, связано с тем, что мы записываем статистику по пользователям в переменную.
- Отсюда можно сделать вывод, если мы будем держать статистику по пользователям не в памяти, а где нибудь ещё (file, redis, etc)
- потребление пямяти снизилось с 958 мегабайт до 90 на обработке большого файла.
- `memore_profiler` показывал незначительное увечеличение в сравнение с предыдущим исправлением (80 мегабайт). Времся работы уменьшилось с 19 до 15 секунд. Из отчёта `valgring-massif` было замечено, что график тем не менее растёт.

### Ваша находка №5
```
Memory usage before: 78 MB
Memory usage after: 90 MB
```
- измерение памяти до начала работы и после окнчания позволило понять, что мы тратим много памяти ещё до начала работы
- убрал не нужные гемы, вызываю гемы только там, где нужны
- в результате проделанной работы, значительно снизилось потребленение памяти, на само выполнение скрипта требуется 5 мегабайт
```
Memory usage before: 17 MB
Memory usage after: 22 MB
```
- из графика `valgring-massif` было замечано, что пямять изначально выделяется для инициализации, и дальше сохраняется на одном уровне на протяжении всего выполнения скрипта.

## Результаты
В результате проделанной оптимизации наконец удалось значительно уменьшить потребление памяти скриптом с 2404 мегабайт до 22 магабайт уложиться в заданный бюджет. Так же удалось увеличить скорость выполнения скрипта с 36 до 12 секунд.

Большинство профилировщиков не показывают потребление памяти во времени. Так же нужно изначалось замерять память до инициализаии скрипта и после, так можно более точно определить, сколько потребовалось памяти на выполнение.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был написан тест производительности
